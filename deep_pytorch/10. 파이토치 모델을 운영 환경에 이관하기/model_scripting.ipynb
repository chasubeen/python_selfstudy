{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 네트워크 정의\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cn1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.cn2 = nn.Conv2d(16, 32, 3, 1)\n",
    "\n",
    "        self.dp1 = nn.Dropout2d(0.10)\n",
    "        self.dp2 = nn.Dropout2d(0.25)\n",
    "\n",
    "        self.fc1 = nn.Linear(4608, 64) # 4608 is basically 12 X 12 X 32\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cn1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.cn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dp1(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        op = F.log_softmax(x, dim = 1)\n",
    "\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 모델 가중치 업데이트\n",
    "\n",
    "PATH_TO_MODEL = \"./convnet.pth\"\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL, map_location = \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 추적\n",
    "\n",
    "model.eval() # 평가\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 스크립팅**\n",
    "- 모델에 더미 입력을 제공하지 않아도 바로 토치스크립트 코드로 변환 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.ConvNet,\n",
       "      %x.1 : Tensor):\n",
       "  %51 : Function = prim::Constant[name=\"log_softmax\"]()\n",
       "  %49 : int = prim::Constant[value=3]()\n",
       "  %33 : int = prim::Constant[value=-1]()\n",
       "  %26 : Function = prim::Constant[name=\"_max_pool2d\"]()\n",
       "  %20 : int = prim::Constant[value=0]()\n",
       "  %19 : NoneType = prim::Constant()\n",
       "  %7 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %6 : bool = prim::Constant[value=0]()\n",
       "  %17 : int = prim::Constant[value=2]() # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:21:28\n",
       "  %32 : int = prim::Constant[value=1]() # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:24:29\n",
       "  %cn1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"cn1\"](%self)\n",
       "  %x.5 : Tensor = prim::CallMethod[name=\"forward\"](%cn1, %x.1) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:16:12\n",
       "  %x.9 : Tensor = prim::CallFunction(%7, %x.5, %6) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:17:12\n",
       "  %cn2 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name=\"cn2\"](%self)\n",
       "  %x.13 : Tensor = prim::CallMethod[name=\"forward\"](%cn2, %x.9) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:19:12\n",
       "  %x.17 : Tensor = prim::CallFunction(%7, %x.13, %6) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:20:12\n",
       "  %18 : int[] = prim::ListConstruct(%17, %17)\n",
       "  %21 : int[] = prim::ListConstruct(%20, %20)\n",
       "  %23 : int[] = prim::ListConstruct(%32, %32)\n",
       "  %x.21 : Tensor = prim::CallFunction(%26, %x.17, %18, %19, %21, %23, %6, %6) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:21:12\n",
       "  %dp1 : __torch__.torch.nn.modules.dropout.Dropout2d = prim::GetAttr[name=\"dp1\"](%self)\n",
       "  %x.25 : Tensor = prim::CallMethod[name=\"forward\"](%dp1, %x.21) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:22:12\n",
       "  %x.29 : Tensor = aten::flatten(%x.25, %32, %33) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:24:12\n",
       "  %fc1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc1\"](%self)\n",
       "  %x.33 : Tensor = prim::CallMethod[name=\"forward\"](%fc1, %x.29) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:26:12\n",
       "  %x.37 : Tensor = prim::CallFunction(%7, %x.33, %6) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:27:12\n",
       "  %dp2 : __torch__.torch.nn.modules.dropout.___torch_mangle_1.Dropout2d = prim::GetAttr[name=\"dp2\"](%self)\n",
       "  %x.41 : Tensor = prim::CallMethod[name=\"forward\"](%dp2, %x.37) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:28:12\n",
       "  %fc2 : __torch__.torch.nn.modules.linear.___torch_mangle_2.Linear = prim::GetAttr[name=\"fc2\"](%self)\n",
       "  %x.45 : Tensor = prim::CallMethod[name=\"forward\"](%fc2, %x.41) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:30:12\n",
       "  %op.1 : Tensor = prim::CallFunction(%51, %x.45, %32, %49, %19) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_20908\\2936341797.py:32:13\n",
       "  return (%op.1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  _0 = __torch__.torch.nn.functional._max_pool2d\n",
      "  _1 = __torch__.torch.nn.functional.log_softmax\n",
      "  cn1 = self.cn1\n",
      "  x0 = (cn1).forward(x, )\n",
      "  x1 = __torch__.torch.nn.functional.relu(x0, False, )\n",
      "  cn2 = self.cn2\n",
      "  x2 = (cn2).forward(x1, )\n",
      "  x3 = __torch__.torch.nn.functional.relu(x2, False, )\n",
      "  x4 = _0(x3, [2, 2], None, [0, 0], [1, 1], False, False, )\n",
      "  dp1 = self.dp1\n",
      "  x5 = (dp1).forward(x4, )\n",
      "  x6 = torch.flatten(x5, 1)\n",
      "  fc1 = self.fc1\n",
      "  x7 = (fc1).forward(x6, )\n",
      "  x8 = __torch__.torch.nn.functional.relu(x7, False, )\n",
      "  dp2 = self.dp2\n",
      "  x9 = (dp2).forward(x8, )\n",
      "  fc2 = self.fc2\n",
      "  x10 = (fc2).forward(x9, )\n",
      "  return _1(x10, 1, 3, None, )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scripted_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(scripted_model, 'scripted_convnet.pt') # 스크립팅한 모델 내보내기\n",
    "\n",
    "loaded_scripted_model = torch.jit.load('scripted_convnet.pt') # 모델 재로딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **스크립팅한 모델을 사용한 추론**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 샘플 이미지 준비\n",
    "\n",
    "image = Image.open(\"./digit_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(image):\n",
    "    gray_image = transforms.functional.to_grayscale(image)\n",
    "    resized_image = transforms.functional.resize(gray_image, (28, 28))\n",
    "    input_image_tensor = transforms.functional.to_tensor(resized_image)\n",
    "    input_image_tensor_norm = transforms.functional.normalize(input_image_tensor, \n",
    "                                                              (0.1302,), (0.3069,))\n",
    "    return input_image_tensor_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = image_to_tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3505e+00, -1.2089e+01, -2.2391e-03, -8.9248e+00, -9.8197e+00,\n",
       "         -1.3350e+01, -9.0460e+00, -1.4492e+01, -6.3023e+00, -1.2283e+01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_scripted_model(input_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추적된 모델과 스크립팅된 모델이 동일한 결과를 도출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
