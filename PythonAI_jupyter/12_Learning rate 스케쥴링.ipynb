{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5380094a",
   "metadata": {},
   "source": [
    "# 1. Learning rate\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8c8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.losses as losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbd46d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true,y_pred):\n",
    "    smooth = 0.\n",
    "    \n",
    "    # Flatten(행렬의 평탄화 -> 자연수 계산을 가능하도록)\n",
    "    y_true = tf.reshape(y_true, [-1]) # 차원 생성\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred) # 교집합\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    \n",
    "    score = intersection / (union+smooth)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def dice_coef(y_true,y_pred):\n",
    "    smooth = 0.\n",
    "    \n",
    "    # Flatten(행렬의 평탄화 -> 자연수 계산을 가능하도록)\n",
    "    y_true = tf.reshape(y_true, [-1]) # 차원 생성\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred) # 교집합 \n",
    "    score = (2 * intersection) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true,y_pred):\n",
    "    loss = 1 - dice_coef(y_true,y_pred)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true,y_pred):\n",
    "    loss = 1. * losses.binary_crossentropy(y_true,y_pred) + 1. * dice_loss(y_true,y_pred)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a896c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "class Augmentation:\n",
    "    def __init__(self, size, mode='train'):\n",
    "        if mode == 'train':\n",
    "            self.transform = A.Compose([\n",
    "                # 수평\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                # 이동, 크기, 회전을 설정\n",
    "                A.ShiftScaleRotate(\n",
    "                    p=0.5,\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=15\n",
    "                ),\n",
    "                # 최대 8개의 구멍을 dropout 하게됨\n",
    "                A.CoarseDropout(\n",
    "                    p=0.5,\n",
    "                    max_holes=8,\n",
    "                    max_height=int(0.1 * size),\n",
    "                    max_width=int(0.1 * size)\n",
    "                ),\n",
    "                A.RandomBrightnessContrast(p=0.2)\n",
    "            ])\n",
    "    \n",
    "    def __call__(self, **kwargs): # {image=image, mask=mask}\n",
    "        if self.transform:\n",
    "            augmented = self.transform(**kwargs)\n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            return img, mask\n",
    "        \n",
    "        \n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, csv_path, fold, image_size, mode='train', shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "        \n",
    "        #### https://github.com/tensorflow/models/issues/3134\n",
    "        #### 파일 이슈 -> 삭제\n",
    "        invalid_filenames = [\n",
    "            'Egyptian_Mau_14',\n",
    "            'Egyptian_Mau_139',\n",
    "            'Egyptian_Mau_145',\n",
    "            'Egyptian_Mau_156',\n",
    "            'Egyptian_Mau_167',\n",
    "            'Egyptian_Mau_177',\n",
    "            'Egyptian_Mau_186',\n",
    "            'Egyptian_Mau_191',\n",
    "            'Abyssinian_5',\n",
    "            'Abyssinian_34',\n",
    "            'chihuahua_121',\n",
    "            'beagle_116'\n",
    "        ]\n",
    "        self.df = self.df[~self.df['file_name'].isin(invalid_filenames)]\n",
    "        self.transform = Augmentation(image_size, mode)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "            return math.ceil(len(self.df) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        strt = idx * self.batch_size\n",
    "        fin = (idx + 1) * self.batch_size\n",
    "        data = self.df.iloc[strt:fin]\n",
    "        batch_x, batch_y = self.get_data(data)\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "        \n",
    "    def get_data(self, data):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for _, r in data.iterrows():\n",
    "            file_name = r['file_name']\n",
    "            image = cv2.imread(f'data/images/{file_name}.jpg')\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "            \n",
    "            mask = cv2.imread(f'data/annotations/trimaps/{file_name}.png', cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.resize(mask, (self.image_size, self.image_size))\n",
    "            mask[mask != 1] = 0\n",
    "            \n",
    "            if self.mode == 'train':\n",
    "                image, mask = self.transform(image=image, mask=mask)\n",
    "            \n",
    "            image = image.astype('float32')            \n",
    "            image = image / 255.\n",
    "            \n",
    "            mask = mask.astype('float32')\n",
    "        \n",
    "            # label = int(r['id']) - 1\n",
    "            \n",
    "            batch_x.append(image)\n",
    "            batch_y.append(mask)\n",
    "            \n",
    "        return batch_x, batch_y\n",
    "\n",
    "    \n",
    "csv_path = 'data/kfolds.csv'\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    batch_size = 128,\n",
    "    csv_path = csv_path,\n",
    "    fold = 1,\n",
    "    image_size = 128,\n",
    "    mode = 'train',\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "valid_generator = DataGenerator(\n",
    "    batch_size = 128,\n",
    "    csv_path = csv_path,\n",
    "    fold = 1,\n",
    "    image_size = 256,\n",
    "    mode = 'val',\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b0cc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4703d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d5175e1e50>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learning rate: 딥러닝 신경망이 확률적 경사 하강법(SGD) 최적화 알고리즘을 사용하여 학습하기 위한 파라미터\n",
    "# learning rate decay: 기존의 Learning Rate가 높은 경우 loss 값을 빠르게 내릴 수 있지만, 최적의 학습을 \n",
    "# 벗어나게 만들고, 낮은 경우 최적의 학습을 할 수 잇지만 너무 오랜 시간이 걸림. 처음 시작 시 Learning rate 값을\n",
    "# 크게 준 후 일정 epoch마다 값을 감소시켜서 최적의 학습까지 더 빠르게 도달할 수 있게 하는 방법\n",
    "def decayed_learning_rate(step):\n",
    "    initial_learning_rate = 0.001\n",
    "    decay_rate = 0.96\n",
    "    decay_steps = 3\n",
    "    \n",
    "    return initial_learning_rate * decay_rate ** (step/decay_steps)\n",
    "\n",
    "lrs = [decayed_learning_rate(i) for i in range(1,46 * 10)]\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad2a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    0.001, # initial_learning_rate\n",
    "    decay_steps = 3,\n",
    "    decay_rate = 0.96\n",
    ")\n",
    "\n",
    "optimizer = optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dba2086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 64  1728        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 128, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " spatial_dropout2d (SpatialDrop  (None, 128, 128, 64  0          ['batch_normalization[0][0]']    \n",
      " out2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 64  36864       ['spatial_dropout2d[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 128)  73728       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_1 (SpatialDr  (None, 64, 64, 128)  0          ['batch_normalization_2[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 128)  147456      ['spatial_dropout2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0          ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 256)  294912      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_2 (SpatialDr  (None, 32, 32, 256)  0          ['batch_normalization_4[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 256)  589824      ['spatial_dropout2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0          ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 512)  1179648     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 512)  2048       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_3 (SpatialDr  (None, 16, 16, 512)  0          ['batch_normalization_6[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 512)  2359296     ['spatial_dropout2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 512)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 1024)   4718592     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 8, 8, 1024)  4096        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_4 (SpatialDr  (None, 8, 8, 1024)  0           ['batch_normalization_8[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 1024)   9437184     ['spatial_dropout2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 1024)  4096        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_transpose (Conv2DTransp  (None, 16, 16, 512)  2097664    ['batch_normalization_9[0][0]']  \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 512)  4718592     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 512)  2359296     ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 256)  524544     ['batch_normalization_11[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 256)  1179648     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 256)  589824      ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 128)  131200     ['batch_normalization_13[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 128)  294912      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 64, 64, 128)  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 128)  147456      ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 64, 64, 128)  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 64  32832      ['batch_normalization_15[0][0]'] \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                8)                                'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 64  73728       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 128, 128, 64  256        ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 64  36864       ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 128, 128, 64  256        ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 128, 1)  65          ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,049,409\n",
      "Trainable params: 31,037,633\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras_unet.models import custom_unet\n",
    "\n",
    "model = custom_unet(\n",
    "    input_shape = (128,128,3), # 데이터를 넣는 형태 설정\n",
    "    use_batch_norm = True, # 정규화\n",
    "    upsample_mode = 'deconv',\n",
    "    dropout_type = 'spatial',\n",
    "    num_classes = 1,\n",
    "    filters = 64,\n",
    "    dropout = 0.2,\n",
    "    num_layers = 4,\n",
    "    output_activation = 'sigmoid'\n",
    ")\n",
    "\n",
    "model.compile(optimizer = 'adam',loss = bce_dice_loss, metrics = [iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e76586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 3/46 [>.............................] - ETA: 1:08:06 - loss: 1.3939 - iou: 0.2649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data = valid_generator,\n",
    "    epochs = 10,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b34947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
