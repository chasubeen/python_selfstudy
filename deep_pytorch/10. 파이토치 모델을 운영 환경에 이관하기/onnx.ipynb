{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 네트워크 정의\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cn1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.cn2 = nn.Conv2d(16, 32, 3, 1)\n",
    "\n",
    "        self.dp1 = nn.Dropout2d(0.10)\n",
    "        self.dp2 = nn.Dropout2d(0.25)\n",
    "\n",
    "        self.fc1 = nn.Linear(4608, 64) # 4608 is basically 12 X 12 X 32\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cn1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.cn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dp1(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        op = F.log_softmax(x, dim = 1)\n",
    "\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 모델 가중치 업데이트\n",
    "\n",
    "PATH_TO_MODEL = \"./convnet.pth\"\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL, map_location = \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 추적\n",
    "\n",
    "model.eval() # 평가\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 스크립팅**\n",
    "- 모델에 더미 입력을 제공하지 않아도 바로 토치스크립트 코드로 변환 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.ConvNet,\n",
       "      %x.1 : Tensor):\n",
       "  %51 : Function = prim::Constant[name=\"log_softmax\"]()\n",
       "  %49 : int = prim::Constant[value=3]()\n",
       "  %33 : int = prim::Constant[value=-1]()\n",
       "  %26 : Function = prim::Constant[name=\"_max_pool2d\"]()\n",
       "  %20 : int = prim::Constant[value=0]()\n",
       "  %19 : None = prim::Constant()\n",
       "  %7 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %6 : bool = prim::Constant[value=0]()\n",
       "  %17 : int = prim::Constant[value=2]() # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:21:28\n",
       "  %32 : int = prim::Constant[value=1]() # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:24:29\n",
       "  %2 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"cn1\"](%self)\n",
       "  %x.3 : Tensor = prim::CallMethod[name=\"forward\"](%2, %x.1) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:16:12\n",
       "  %x.5 : Tensor = prim::CallFunction(%7, %x.3, %6) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:17:12\n",
       "  %9 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name=\"cn2\"](%self)\n",
       "  %x.7 : Tensor = prim::CallMethod[name=\"forward\"](%9, %x.5) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:19:12\n",
       "  %x.9 : Tensor = prim::CallFunction(%7, %x.7, %6) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:20:12\n",
       "  %18 : int[] = prim::ListConstruct(%17, %17)\n",
       "  %21 : int[] = prim::ListConstruct(%20, %20)\n",
       "  %23 : int[] = prim::ListConstruct(%32, %32)\n",
       "  %x.11 : Tensor = prim::CallFunction(%26, %x.9, %18, %19, %21, %23, %6, %6) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:21:12\n",
       "  %28 : __torch__.torch.nn.modules.dropout.Dropout2d = prim::GetAttr[name=\"dp1\"](%self)\n",
       "  %x.13 : Tensor = prim::CallMethod[name=\"forward\"](%28, %x.11) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:22:12\n",
       "  %x.15 : Tensor = aten::flatten(%x.13, %32, %33) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:24:12\n",
       "  %35 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc1\"](%self)\n",
       "  %x.17 : Tensor = prim::CallMethod[name=\"forward\"](%35, %x.15) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:26:12\n",
       "  %x.19 : Tensor = prim::CallFunction(%7, %x.17, %6) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:27:12\n",
       "  %42 : __torch__.torch.nn.modules.dropout.___torch_mangle_1.Dropout2d = prim::GetAttr[name=\"dp2\"](%self)\n",
       "  %x.21 : Tensor = prim::CallMethod[name=\"forward\"](%42, %x.19) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:28:12\n",
       "  %45 : __torch__.torch.nn.modules.linear.___torch_mangle_2.Linear = prim::GetAttr[name=\"fc2\"](%self)\n",
       "  %x.23 : Tensor = prim::CallMethod[name=\"forward\"](%45, %x.21) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:30:12\n",
       "  %op.1 : Tensor = prim::CallFunction(%51, %x.23, %32, %49, %19) # C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\2936341797.py:32:13\n",
       "  return (%op.1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  _0 = __torch__.torch.nn.functional._max_pool2d\n",
      "  _1 = __torch__.torch.nn.functional.log_softmax\n",
      "  x0 = (self.cn1).forward(x, )\n",
      "  x1 = __torch__.torch.nn.functional.relu(x0, False, )\n",
      "  x2 = (self.cn2).forward(x1, )\n",
      "  x3 = __torch__.torch.nn.functional.relu(x2, False, )\n",
      "  x4 = _0(x3, [2, 2], None, [0, 0], [1, 1], False, False, )\n",
      "  x5 = (self.dp1).forward(x4, )\n",
      "  x6 = torch.flatten(x5, 1, -1)\n",
      "  x7 = (self.fc1).forward(x6, )\n",
      "  x8 = __torch__.torch.nn.functional.relu(x7, False, )\n",
      "  x9 = (self.dp2).forward(x8, )\n",
      "  x10 = (self.fc2).forward(x9, )\n",
      "  return _1(x10, 1, 3, None, )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scripted_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(scripted_model, 'scripted_convnet.pt') # 스크립팅한 모델 내보내기\n",
    "\n",
    "loaded_scripted_model = torch.jit.load('scripted_convnet.pt') # 모델 재로딩하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **스크립팅한 모델을 사용한 추론**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 샘플 이미지 준비\n",
    "\n",
    "image = Image.open(\"./digit_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(image):\n",
    "    gray_image = transforms.functional.to_grayscale(image)\n",
    "    resized_image = transforms.functional.resize(gray_image, (28, 28))\n",
    "    input_image_tensor = transforms.functional.to_tensor(resized_image)\n",
    "    input_image_tensor_norm = transforms.functional.normalize(input_image_tensor, \n",
    "                                                              (0.1302,), (0.3069,))\n",
    "    return input_image_tensor_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = image_to_tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3505e+00, -1.2089e+01, -2.2391e-03, -8.9248e+00, -9.8197e+00,\n",
       "         -1.3350e+01, -9.0460e+00, -1.4492e+01, -6.3023e+00, -1.2283e+01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_scripted_model(input_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ONNX로 파이토치 모델 내보내기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델 ONNX 파일 저장**  \n",
    "- 내부적으로는 모델 추적에 사용했던 것과 동일한 메커니즘을 사용해 모델 직렬화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_input = torch.ones(1,1,28,28)\n",
    "torch.onnx.export(model, demo_input, \"convnet.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**저장한 onnx 모델 로딩**  \n",
    "- 직렬화된 tensorflow 모델로 변환\n",
    "- 이후 모델 아키텍처를 제대로 로딩했는지 확인하고 그래프의 입출력 노드를 식별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx as onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "model_onnx = onnx.load(\"./convnet.onnx\")\n",
    "tf_rep = prepare(model_onnx)\n",
    "tf_rep.export_graph(\"./convnet.pb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델 그래프 파싱**  \n",
    "- 모델 아키텍처를 제대로 로딩했는지 확인\n",
    "- 그래프의 입출력 노드 식별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\3903909357.py:3: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\3903909357.py:4: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "(<tf.Tensor 'Const:0' shape=(16, 1, 3, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_1:0' shape=(16,) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_2:0' shape=(32, 16, 3, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_3:0' shape=(32,) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_4:0' shape=(64, 4608) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_5:0' shape=(64,) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_6:0' shape=(10, 64) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_7:0' shape=(10,) dtype=float32>,)\n",
      "(<tf.Tensor 'input.1:0' shape=(1, 1, 28, 28) dtype=float32>,)\n",
      "(<tf.Tensor 'transpose/perm:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'transpose:0' shape=(3, 3, 1, 16) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_8:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'split/split_dim:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'split:0' shape=(3, 3, 1, 16) dtype=float32>,)\n",
      "(<tf.Tensor 'transpose_1/perm:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'transpose_1:0' shape=(1, 28, 28, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_9:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'split_1/split_dim:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'split_1:0' shape=(1, 28, 28, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'convolution:0' shape=(1, 26, 26, 16) dtype=float32>,)\n",
      "(<tf.Tensor 'concat/concat_dim:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'concat/concat:0' shape=(1, 26, 26, 16) dtype=float32>,)\n",
      "(<tf.Tensor 'Add:0' shape=(1, 26, 26, 16) dtype=float32>,)\n",
      "(<tf.Tensor 'transpose_2/perm:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'transpose_2:0' shape=(1, 16, 26, 26) dtype=float32>,)\n",
      "(<tf.Tensor 'Relu_1:0' shape=(1, 16, 26, 26) dtype=float32>,)\n",
      "(<tf.Tensor 'transpose_3/perm:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'transpose_3:0' shape=(3, 3, 16, 32) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_10:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'split_2/split_dim:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'split_2:0' shape=(3, 3, 16, 32) dtype=float32>,)\n",
      "(<tf.Tensor 'transpose_4/perm:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'transpose_4:0' shape=(1, 26, 26, 16) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_11:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'split_3/split_dim:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'split_3:0' shape=(1, 26, 26, 16) dtype=float32>,)\n",
      "(<tf.Tensor 'convolution_1:0' shape=(1, 24, 24, 32) dtype=float32>,)\n",
      "(<tf.Tensor 'concat_1/concat_dim:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'concat_1/concat:0' shape=(1, 24, 24, 32) dtype=float32>,)\n",
      "(<tf.Tensor 'Add_1:0' shape=(1, 24, 24, 32) dtype=float32>,)\n",
      "(<tf.Tensor 'transpose_5/perm:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'transpose_5:0' shape=(1, 32, 24, 24) dtype=float32>,)\n",
      "(<tf.Tensor 'Relu_3:0' shape=(1, 32, 24, 24) dtype=float32>,)\n",
      "(<tf.Tensor 'transpose_6/perm:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'transpose_6:0' shape=(1, 24, 24, 32) dtype=float32>,)\n",
      "(<tf.Tensor 'max_pool/dilation_rate:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'max_pool:0' shape=(1, 12, 12, 32) dtype=float32>,)\n",
      "(<tf.Tensor 'transpose_7/perm:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'transpose_7:0' shape=(1, 32, 12, 12) dtype=float32>,)\n",
      "(<tf.Tensor 'Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'Flatten_5/Reshape/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'Flatten_5/Reshape:0' shape=(1, 4608) dtype=float32>,)\n",
      "(<tf.Tensor 'flatten/Reshape/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'flatten/Reshape:0' shape=(1, 4608) dtype=float32>,)\n",
      "(<tf.Tensor 'transpose_8/perm:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'transpose_8:0' shape=(4608, 64) dtype=float32>,)\n",
      "(<tf.Tensor 'MatMul:0' shape=(1, 64) dtype=float32>,)\n",
      "(<tf.Tensor 'mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'mul:0' shape=(1, 64) dtype=float32>,)\n",
      "(<tf.Tensor 'mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'mul_1:0' shape=(64,) dtype=float32>,)\n",
      "(<tf.Tensor 'add_2:0' shape=(1, 64) dtype=float32>,)\n",
      "(<tf.Tensor 'Relu_7:0' shape=(1, 64) dtype=float32>,)\n",
      "(<tf.Tensor 'flatten_1/Reshape/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'flatten_1/Reshape:0' shape=(1, 64) dtype=float32>,)\n",
      "(<tf.Tensor 'transpose_9/perm:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'transpose_9:0' shape=(64, 10) dtype=float32>,)\n",
      "(<tf.Tensor 'MatMul_1:0' shape=(1, 10) dtype=float32>,)\n",
      "(<tf.Tensor 'mul_2/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'mul_2:0' shape=(1, 10) dtype=float32>,)\n",
      "(<tf.Tensor 'mul_3/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'mul_3:0' shape=(10,) dtype=float32>,)\n",
      "(<tf.Tensor 'add_3:0' shape=(1, 10) dtype=float32>,)\n",
      "(<tf.Tensor '18:0' shape=(1, 10) dtype=float32>,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.gfile.GFile(\"./convnet.pb\", \"rb\") as f:\n",
    "    graph_definition = tf.GraphDef()\n",
    "    graph_definition.ParseFromString(f.read())\n",
    "    \n",
    "with tf.Graph().as_default() as model_graph:\n",
    "    tf.import_graph_def(graph_definition, name=\"\")\n",
    "    \n",
    "for op in model_graph.get_operations():\n",
    "    print(op.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력과 출력 노드를 식별할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**샘플 이미지에 대한 예측 생성**\n",
    "- 변수를 신경망 모델의 입력과 출력 노드에 할당하고 tensorflow session을 인스턴스화해서 그래프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\doroc\\AppData\\Local\\Temp\\ipykernel_26416\\1008460273.py:4: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "[[-9.35050774e+00 -1.20893326e+01 -2.23910273e-03 -8.92477798e+00\n",
      "  -9.81972313e+00 -1.33498535e+01 -9.04598618e+00 -1.44924192e+01\n",
      "  -6.30233145e+00 -1.22827682e+01]]\n"
     ]
    }
   ],
   "source": [
    "model_output = model_graph.get_tensor_by_name('18:0')\n",
    "model_input = model_graph.get_tensor_by_name('input.1:0')\n",
    "\n",
    "sess = tf.Session(graph=model_graph)\n",
    "output = sess.run(model_output, \n",
    "                  feed_dict={model_input: input_tensor.unsqueeze(0)})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
