{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7x7I3T0wmykZrxFqj7yEB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chasubeen/python_selfstudy/blob/master/deep_pytorch/4.%20%EC%8B%AC%EC%B8%B5%20%EC%88%9C%ED%99%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **감성 분석을 위한 RNN 훈련하기**"
      ],
      "metadata": {
        "id": "Vg6sVWSkRA2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **텍스트 데이터셋 로딩 및 전처리**"
      ],
      "metadata": {
        "id": "RMPhaA7wS1aI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1) Import Libraries**"
      ],
      "metadata": {
        "id": "FZ5gfBZLTCJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "# 문자열 처리를 위한 라이브러리\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWJlO0a5S68h",
        "outputId": "a7a3580a-b095-472d-e0a4-30620c03294b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79a9785059f0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2) 데이터 파일 불러오기**\n",
        "- IMDB 감성 분석 데이터셋을 사용\n",
        "  - 영화 리뷰 텍스트와 그에 해당하는 감성 레이블로 구성됨"
      ],
      "metadata": {
        "id": "D5JP6FZsTFF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tzTbVtYrnFq",
        "outputId": "3059f932-c15f-4042-d833-925d530e091d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 텍스트 파일에서 리뷰 데이터와 감성 레이블 읽어오기\n",
        "\n",
        "review_list = [] # Feature\n",
        "label_list = [] # Target\n",
        "for label in ['pos', 'neg']:\n",
        "  for fname in tqdm(os.listdir(f'/content/drive/MyDrive/딥러닝 공부/실전! 파이토치 딥러닝 프로젝트/data/aclImdb/train/{label}/')):\n",
        "    if 'txt' not in fname:\n",
        "      continue\n",
        "    with open(os.path.join(f'/content/drive/MyDrive/딥러닝 공부/실전! 파이토치 딥러닝 프로젝트/data/aclImdb/train/{label}/', fname), encoding=\"utf8\") as f:\n",
        "      review_list += [f.read()]\n",
        "      label_list += [label]\n",
        "print ('Number of reviews :', len(review_list))"
      ],
      "metadata": {
        "id": "Bv94GGKHToeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f05a0d4-d339-4686-e210-5c590a21964f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12500/12500 [06:24<00:00, 32.49it/s] \n",
            "100%|██████████| 12500/12500 [09:48<00:00, 21.22it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews : 25000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3) 데이터 로딩**\n",
        "- 텍스트 데이터 전처리\n",
        "  - 먼저 전체 텍스트 말뭉치(corpus)를 소문자로 처리한 다음, 리뷰 텍스트에서 구두점을 모두 제거함\n",
        "  - 그런 다음 전체 리뷰에 나오는 단어를 모두 모아 단어 등장 횟수를 계산하고 가장 많이 사용되는 단어를 확인하기 위해 단어 등장 횟수 기준으로 내림차순 정렬함\n"
      ],
      "metadata": {
        "id": "vBWGLwGl0nRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 리뷰 텍스트 전처리\n",
        "review_list = [review.lower() for review in review_list]\n",
        "review_list = [''.join([letter for letter in review if letter not in punctuation]) for review in tqdm(review_list)]\n",
        "\n",
        "# 전체 리뷰 텍스트 축적\n",
        "reviews_blob = ' '.join(review_list)\n",
        "\n",
        "# 전체 리뷰에서 나오는 모든 단어를 리스트로 생성\n",
        "review_words = reviews_blob.split()\n",
        "\n",
        "# 단어 등장 횟수 가져오기\n",
        "count_words = Counter(review_words)\n",
        "\n",
        "# 등장 횟수로 단어 정렬(내림차순)\n",
        "total_review_words = len(review_words)\n",
        "sorted_review_words = count_words.most_common(total_review_words)\n",
        "\n",
        "print(sorted_review_words[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5iBMjT35Bbr",
        "outputId": "8930e549-9a3d-4d5e-e86a-85f4f8a00a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [00:01<00:00, 18041.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 334691), ('and', 162228), ('a', 161940), ('of', 145326), ('to', 135042), ('is', 106855), ('in', 93028), ('it', 77099), ('i', 75719), ('this', 75190)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 가장 많이 등장하는 단어는 명사가 아닌 한정사, 대명사 같은 것들임\n",
        "- 일반적으로 명사가 아닌 단어(불용어)는 많은 의미를 전달하지 않으므로 말뭉치에서 제거됨\n",
        "  - 현재는 일단 제거하지 않고 넘어감"
      ],
      "metadata": {
        "id": "lW2zEgn85_ME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4) 인코딩**\n",
        "- 머신러닝 모델은 단어가 아니라 숫자만 이해함\n",
        "  - 개별 단어를 숫자 또는 토큰으로 변환하는 작업이 필요\n",
        "  "
      ],
      "metadata": {
        "id": "d7ahYQoi6C01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**사전 구축**  \n",
        "단어-정수 매핑 얻기"
      ],
      "metadata": {
        "id": "qAWrYQA77m6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트를 숫자로 인코딩하기 위해 단러-정수(토큰) 딕셔너리를 생성\n",
        "\n",
        "vocab_to_token = {word:idx + 1 for idx, (word, count) in enumerate(sorted_review_words)}\n",
        "print(list(vocab_to_token.items())[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-qyk4Ic5q9a",
        "outputId": "79e8a3f8-6b84-4fe2-c2fb-321eb92036ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5), ('is', 6), ('in', 7), ('it', 8), ('i', 9), ('this', 10)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 가장 많이 등장하는 단어에 1을 시작으로 순서대로 단어에 숫자가 할당됨"
      ],
      "metadata": {
        "id": "9WZvkMjm63PQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**리뷰 -> 숫자**  \n",
        "위에서 구축한 사전을 사용해 숫자 리스트로 변환"
      ],
      "metadata": {
        "id": "-k0xvGR_7gjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_tokenized = []\n",
        "\n",
        "for review in review_list:\n",
        "  word_to_token = [vocab_to_token[word] for word in review.split()]\n",
        "  reviews_tokenized.append(word_to_token)\n",
        "\n",
        "print(review_list[0])\n",
        "print()\n",
        "print(reviews_tokenized[0])"
      ],
      "metadata": {
        "id": "oRd1PKzd8HKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**긍정/부정**  \n",
        "감성 분류값을 숫자로 인코딩하는 과정이 필요"
      ],
      "metadata": {
        "id": "ocQXlZ5U8RDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 감성을 0 또는 1로 인코딩\n",
        "encoded_label_list = [1 if label =='pos' else 0 for label in label_list]\n",
        "\n",
        "reviews_len = [len(review) for review in reviews_tokenized]\n",
        "\n",
        "reviews_tokenized = [reviews_tokenized[i] for i, l in enumerate(reviews_len) if l > 0 ]\n",
        "encoded_label_list = np.array([encoded_label_list[i] for i, l in enumerate(reviews_len) if l> 0 ], dtype='float32')"
      ],
      "metadata": {
        "id": "tVuAtiI58q5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5) 정규화**\n",
        "- 리뷰가 다양하므로 길이 또한 다양할 수 있음\n",
        "  - 그러나 모델은 고정된 길이가 입력되기를 기대함\n",
        "- 다양한 길이의 리뷰를 정규화 해 모두 같은 길이를 갖도록 만들어줌\n",
        "  - 시퀀스 길이 L(여기서는 512)을 정의한 다음 L보다 길이가 짧은 시퀀스에는 패딩을 가하고 L보다 긴 시퀀스는 잘라냄"
      ],
      "metadata": {
        "id": "3IL3wLCA9Bjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(reviews_tokenized, sequence_length):\n",
        "  ''' 0으로 패딩되거나 sequence_length에 맞춰 잘린, 토큰화된 리뷰 시퀀스를 반환\n",
        "  '''\n",
        "  padded_reviews = np.zeros((len(reviews_tokenized), sequence_length), dtype = int)\n",
        "\n",
        "  for idx, review in enumerate(reviews_tokenized):\n",
        "    review_len = len(review)\n",
        "\n",
        "    if review_len <= sequence_length:\n",
        "      zeroes = list(np.zeros(sequence_length - review_len))\n",
        "      new_sequence = zeroes+review\n",
        "    elif review_len > sequence_length:\n",
        "      new_sequence = review[0:sequence_length]\n",
        "\n",
        "    padded_reviews[idx,:] = np.array(new_sequence)\n",
        "\n",
        "  return padded_reviews"
      ],
      "metadata": {
        "id": "jnsbY5UO-LS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 512 # 고정된 길이\n",
        "padded_reviews = pad_sequence(reviews_tokenized=reviews_tokenized, sequence_length=sequence_length)\n",
        "\n",
        "plt.hist(reviews_len);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "SPxsonkh-Z95",
        "outputId": "866b3e46-9d0f-435f-929a-806f48bc115b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 대부분의 리뷰는 500 단어보다 짧은 것을 확인할 수 있음\n",
        "- 모델에 사용할 시퀀스 길이로 512를 선택하고 정확히 512 단어 길이가 아닌 시퀀스를 그에 맞춰 수정"
      ],
      "metadata": {
        "id": "acDNIALW-68I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 훈련**"
      ],
      "metadata": {
        "id": "hCJvlr5P-4LZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1) 데이터셋 분리**"
      ],
      "metadata": {
        "id": "jCQ1GXmw_luQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_split = 0.75\n",
        "\n",
        "# 훈련 데이터셋과 검증 데이터셋으로 분리\n",
        "train_X = padded_reviews[:int(train_val_split*len(padded_reviews))]\n",
        "train_y = encoded_label_list[:int(train_val_split*len(padded_reviews))]\n",
        "\n",
        "validation_X = padded_reviews[int(train_val_split*len(padded_reviews)):]\n",
        "validation_y = encoded_label_list[int(train_val_split*len(padded_reviews)):]"
      ],
      "metadata": {
        "id": "_U6MZGN0_HAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2) Dataset, DataLoader 정의**"
      ],
      "metadata": {
        "id": "YDYHcHzk_f9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch 데이터셋 생성\n",
        "train_dataset = TensorDataset(torch.from_numpy(train_X).to(device), torch.from_numpy(train_y).to(device))\n",
        "validation_dataset = TensorDataset(torch.from_numpy(validation_X).to(device), torch.from_numpy(validation_y).to(device))\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# 토치 데이터로더(데이터 shuffle)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "QKVNd-7U_qM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3) 데이터 시각화**\n",
        "- 데이터 구성을 확인하기 위해 32개 리뷰와 그에 해당하는 감성 레이블을 하나의 배치로 하여 시각화"
      ],
      "metadata": {
        "id": "zPeEJx7hAk5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 배치 가져오기\n",
        "train_data_iter = iter(train_dataloader)\n",
        "X_example, y_example = next(train_data_iter)\n",
        "print('Example Input size: ', X_example.size()) # batch_size, seq_length\n",
        "print('Example Input:\\n', X_example)\n",
        "print()\n",
        "print('Example Output size: ', y_example.size()) # batch_size\n",
        "print('Example Output:\\n', y_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08WpRHHkAvoP",
        "outputId": "64b10bb0-0aac-41a5-a8ed-31ffba537986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Input size:  torch.Size([32, 512])\n",
            "Example Input:\n",
            " tensor([[    0,     0,     0,  ...,    27,     3,   861],\n",
            "        [    0,     0,     0,  ...,    72,  6945,   309],\n",
            "        [    0,     0,     0,  ...,    23,    37,  4482],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,   235,    35,  8111],\n",
            "        [    0,     0,     0,  ...,     8,     6,  4982],\n",
            "        [    0,     0,     0,  ..., 16680,   147,   597]])\n",
            "\n",
            "Example Output size:  torch.Size([32])\n",
            "Example Output:\n",
            " tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
            "        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 인스턴스화 및 훈련**"
      ],
      "metadata": {
        "id": "fmErGE51EVFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1) 래퍼 RNN 클래스 정의**\n",
        "- 임베딩 계층으로 시작해 RNN 계층, 마지막으로 완전 연결 계층으로 이어지는 전체 RNN 모델을 인스턴스화\n",
        "- 임베딩 계층의 기능\n",
        "  - 단어 임베딩을 저장하고(룩업 테이블 형태로) 인덱스를 사용해 가져오는 것\n",
        "  > `nn.Embedding` 모듈에서 제공됨"
      ],
      "metadata": {
        "id": "09f3x3_JEZB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_dimension, embedding_dimension, hidden_dimension, output_dimension):\n",
        "    super().__init__()\n",
        "    self.embedding_layer = nn.Embedding(input_dimension, embedding_dimension)\n",
        "    self.rnn_layer = nn.RNN(embedding_dimension, hidden_dimension, num_layers = 1)\n",
        "    self.fc_layer = nn.Linear(hidden_dimension, output_dimension)\n",
        "\n",
        "  def forward(self, sequence):\n",
        "    # sequence shape = (sequence_length, batch_size)\n",
        "    embedding = self.embedding_layer(sequence)\n",
        "\n",
        "    # embedding shape = [sequence_length, batch_size, embedding_dimension]\n",
        "    output, hidden_state = self.rnn_layer(embedding)\n",
        "\n",
        "    # output shape = [sequence_length, batch_size, hidden_dimension]\n",
        "    # hidden_state shape = [1, batch_size, hidden_dimension]\n",
        "    final_output = self.fc_layer(hidden_state[-1,:,:].squeeze(0))\n",
        "\n",
        "    return final_output"
      ],
      "metadata": {
        "id": "GCjYn4ZkE043"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2) RNN 모델 인스턴스화**"
      ],
      "metadata": {
        "id": "7-EUOVaxFlit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dimension = len(vocab_to_token) + 1 # +1 to account for padding\n",
        "embedding_dimension = 100\n",
        "hidden_dimension = 32\n",
        "output_dimension = 1\n",
        "\n",
        "rnn_model = RNN(input_dimension, embedding_dimension, hidden_dimension, output_dimension)\n",
        "\n",
        "optim = torch.optim.Adam(rnn_model.parameters()) # 시그모이드 함수에 대해 수치적으로 안정적인 계산을 제공\n",
        "loss_func = nn.BCEWithLogitsLoss() # 이진 분류 문제에 필수적인 손실 함수\n",
        "\n",
        "rnn_model = rnn_model.to(device)\n",
        "loss_func = loss_func.to(device)"
      ],
      "metadata": {
        "id": "UUg5U3WhEfJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3) 평가 지표 정의**\n",
        "- 훈련된 모델의 성능을 검증 셋에서 측정하기 위한 지표로 정확도를 정의"
      ],
      "metadata": {
        "id": "zNE8eCkAGCAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_metric(predictions, ground_truth):\n",
        "  \"\"\"\n",
        "  예측과 실젯값의 집합이 주어졌을 때 정확도를 0 또는 1로 반환\n",
        "  \"\"\"\n",
        "\n",
        "  # 예측을 0 또는 1로 반올림\n",
        "  rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
        "\n",
        "  success = (rounded_predictions == ground_truth).float() # 나눗셈을 위해 부동소수점으로 변환\n",
        "  accuracy = success.sum() / len(success)\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "a6GgZtJRGiz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4) 훈련/검증 루틴 정의**"
      ],
      "metadata": {
        "id": "-9CPMnrqG_2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optim, loss_func):\n",
        "  loss = 0\n",
        "  accuracy = 0\n",
        "  model.train()\n",
        "\n",
        "  for sequence, sentiment in dataloader:\n",
        "    optim.zero_grad()\n",
        "    preds = model(sequence.T).squeeze()\n",
        "\n",
        "    loss_curr = loss_func(preds, sentiment)\n",
        "    accuracy_curr = accuracy_metric(preds, sentiment)\n",
        "\n",
        "    loss_curr.backward()\n",
        "    optim.step()\n",
        "\n",
        "    loss += loss_curr.item()\n",
        "    accuracy += accuracy_curr.item()\n",
        "\n",
        "  return loss/len(dataloader), accuracy/len(dataloader)"
      ],
      "metadata": {
        "id": "rY1oBt3NHFVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dataloader, loss_func):\n",
        "  loss = 0\n",
        "  accuracy = 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for sequence, sentiment in dataloader:\n",
        "\n",
        "      preds = model(sequence.T).squeeze()\n",
        "\n",
        "      loss_curr = loss_func(preds, sentiment)\n",
        "      accuracy_curr = accuracy_metric(preds, sentiment)\n",
        "\n",
        "      loss += loss_curr.item()\n",
        "      accuracy += accuracy_curr.item()\n",
        "\n",
        "  return loss/len(dataloader), accuracy/len(dataloader)"
      ],
      "metadata": {
        "id": "G2FkYbafHYNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5) Run!!**"
      ],
      "metadata": {
        "id": "lju4j0EnHuwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "best_validation_loss = float('inf')\n",
        "\n",
        "for ep in range(num_epochs):\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  training_loss, train_accuracy = train(rnn_model, train_dataloader, optim, loss_func)\n",
        "  validation_loss, validation_accuracy = validate(rnn_model, validation_dataloader, loss_func)\n",
        "\n",
        "  time_end = time.time()\n",
        "  time_delta = time_end - time_start\n",
        "\n",
        "  if validation_loss < best_validation_loss:\n",
        "    best_validation_loss = validation_loss\n",
        "    torch.save(rnn_model.state_dict(), '/content/drive/MyDrive/딥러닝 공부/실전! 파이토치 딥러닝 프로젝트/model/rnn_model.pt')\n",
        "\n",
        "  print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
        "  print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
        "  print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9tZ4aMbHxZ3",
        "outputId": "fec72b21-22ec-45ea-b520-59378e96a6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number: 1 | time elapsed: 114.01887130737305s\n",
            "training loss: 0.618 | training accuracy: 67.01%\n",
            "validation loss: 1.030 |  validation accuracy: 26.49%\n",
            "\n",
            "epoch number: 2 | time elapsed: 115.90502738952637s\n",
            "training loss: 0.541 | training accuracy: 73.50%\n",
            "validation loss: 0.812 |  validation accuracy: 57.24%\n",
            "\n",
            "epoch number: 3 | time elapsed: 112.71386194229126s\n",
            "training loss: 0.460 | training accuracy: 79.21%\n",
            "validation loss: 0.867 |  validation accuracy: 53.63%\n",
            "\n",
            "epoch number: 4 | time elapsed: 109.81068730354309s\n",
            "training loss: 0.387 | training accuracy: 83.39%\n",
            "validation loss: 0.931 |  validation accuracy: 57.20%\n",
            "\n",
            "epoch number: 5 | time elapsed: 110.89599919319153s\n",
            "training loss: 0.315 | training accuracy: 87.27%\n",
            "validation loss: 0.966 |  validation accuracy: 57.97%\n",
            "\n",
            "epoch number: 6 | time elapsed: 110.48675274848938s\n",
            "training loss: 0.268 | training accuracy: 89.50%\n",
            "validation loss: 1.003 |  validation accuracy: 60.75%\n",
            "\n",
            "epoch number: 7 | time elapsed: 110.22961235046387s\n",
            "training loss: 0.223 | training accuracy: 91.57%\n",
            "validation loss: 1.018 |  validation accuracy: 61.21%\n",
            "\n",
            "epoch number: 8 | time elapsed: 111.06631779670715s\n",
            "training loss: 0.209 | training accuracy: 91.99%\n",
            "validation loss: 0.989 |  validation accuracy: 64.44%\n",
            "\n",
            "epoch number: 9 | time elapsed: 110.59821963310242s\n",
            "training loss: 0.191 | training accuracy: 92.89%\n",
            "validation loss: 1.116 |  validation accuracy: 56.14%\n",
            "\n",
            "epoch number: 10 | time elapsed: 111.37878322601318s\n",
            "training loss: 0.178 | training accuracy: 93.71%\n",
            "validation loss: 1.084 |  validation accuracy: 63.61%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 해당 모델은 과적합되어 훈련셋에서 특히 학습이 잘되는 것으로 보임\n",
        "  - 시간 차원에서 512 계층이나 가짐\n",
        "- 검증 셋에서의 모델 성능은 낮은 값에서 시작해 변동을 거듭하며 높아짐"
      ],
      "metadata": {
        "id": "_AM3M6DTM6lU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6) 추론**\n",
        "- 훈련된 모델에서 실시간 추론을 만드는 헬퍼 함수를 정의하자."
      ],
      "metadata": {
        "id": "kLQCcjemNLgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_inference(model, sentence):\n",
        "  model.eval()\n",
        "\n",
        "  # 텍스트 변환\n",
        "  sentence = sentence.lower()\n",
        "  sentence = ''.join([c for c in sentence if c not in punctuation])\n",
        "  tokenized = [vocab_to_token.get(token, 0) for token in sentence.split()]\n",
        "  tokenized = np.pad(tokenized, (512 - len(tokenized), 0), 'constant')\n",
        "\n",
        "  # 모델 추론\n",
        "  model_input = torch.LongTensor(tokenized).to(device)\n",
        "  model_input = model_input.unsqueeze(1)\n",
        "  pred = torch.sigmoid(model(model_input))\n",
        "\n",
        "  return pred.item()"
      ],
      "metadata": {
        "id": "5eRJr5MhNRo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7) 성능 테스트**\n",
        "- 수작업으로 입력된 리뷰 텍스트를 가지고 해당 모델의 성능을 테스트 해보자."
      ],
      "metadata": {
        "id": "Uy9dRhQpNljG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_inference(rnn_model, \"This film is horrible\"))\n",
        "print(sentiment_inference(rnn_model, \"Director tried too hard but this film is bad\"))\n",
        "print(sentiment_inference(rnn_model, \"Decent movie, although could be shorter\"))\n",
        "print(sentiment_inference(rnn_model, \"This film will be houseful for weeks\"))\n",
        "print(sentiment_inference(rnn_model, \"I loved the movie, every part of it\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFhdxPikNqsl",
        "outputId": "dc2fc62c-268c-43fb-dcd2-b977807b494e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13285593688488007\n",
            "0.7610068321228027\n",
            "0.9503389596939087\n",
            "0.9979846477508545\n",
            "0.9543998837471008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델은 긍정과 부정 의견 중 하나를 선택함\n",
        "- 512 단어보다 훨씬 짧은 경우에도 다양한 길이의 시퀀스를 처리할 수 있음"
      ],
      "metadata": {
        "id": "FwcP9O4mN15w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **양방향 LSTM 만들기**\n",
        "- LSTM은 시간 단계상 몇 단계 전이라도 중요한 정보는 보존하고 최근 정보라도 관련 없는 정보는 망각하는 데 도움이 되는 메모리 셀 게이트가 존재\n",
        "  - 더 긴 시퀀스를 잘 처리할 수 있게 됨\n",
        "> 비교적 긴 텍스트를 처리할 때 LSTM의 성능이 더 좋음\n",
        "\n",
        "- 모델이 영화 리뷰의 감성에 대해 좀 더 정보에 입각한 결정을 내릴 수 있도록 원할 때 context window를 확장할 수 있도록 양방향 모델을 활용"
      ],
      "metadata": {
        "id": "hMCWxYv2NN4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **텍스트 데이터셋 로딩과 전처리**\n",
        "- 파이토치의 `torchtext` 모듈을 활용\n",
        "  - torchtext.dataset 내의 IMDB 데이터셋을 로딩해 사용\n",
        "  - 단어를 토큰화하고 사전을 생성하기 위해 `torchtext.dataset`을 활용\n",
        "  - 시퀀스에 패딩을 수작업으로 하지 않고 `nn.LSTM` 모듈을 사용해 바로 패딩을 진행"
      ],
      "metadata": {
        "id": "787QqGzzOLOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **준비사항**"
      ],
      "metadata": {
        "id": "FnHoyLCESwr_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **a) Import Libraries**"
      ],
      "metadata": {
        "id": "4YPyjyFcNPw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "GhNjLRUXOhQ6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMmESPHiQPzw",
        "outputId": "a9b89482-c38a-4e41-a448-51c65de82d56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c3ec68a7770>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b) 데이터셋 준비**"
      ],
      "metadata": {
        "id": "_1oZkmDpQS_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torchtext import (data, datasets)"
      ],
      "metadata": {
        "id": "TLVsgdT3Qcqr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_FIELD = data.Field(tokenize = data.get_tokenizer(\"basic_english\"), include_lengths = True)\n",
        "LABEL_FIELD = data.LabelField(dtype = torch.float)\n",
        "\n",
        "train_dataset, test_dataset = datasets.IMDB.splits(TEXT_FIELD, LABEL_FIELD)\n",
        "train_dataset, valid_dataset = train_dataset.split(random_state = random.seed(123))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7Sq6zbCRXDY",
        "outputId": "8d42e2ea-bf1b-426d-c0bc-f31c7f5b6e2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|                                               | 0.00/84.1M [00:00<?, ?B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████████████████████████████████| 84.1M/84.1M [00:03<00:00, 27.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **c) 리뷰 데이터셋과 감성 레이블에 대한 사전 구성**\n",
        "- `torchtext.data.Field`와 `torchtext.data.LabelField`의 `build_vocab()` 메서드를 사용해 영화 리뷰 텍스트 데이터셋과 감성 레이블에 대한 사전 구성"
      ],
      "metadata": {
        "id": "1CWVIb46U689"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCABULARY_SIZE = 25000\n",
        "\n",
        "TEXT_FIELD.build_vocab(train_dataset,\n",
        "                 max_size = MAX_VOCABULARY_SIZE)\n",
        "\n",
        "LABEL_FIELD.build_vocab(train_dataset)"
      ],
      "metadata": {
        "id": "XZnf4KSYVlI4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM 모델 인스턴스화 및 훈련**\n",
        "- LSTM 모델 객체를 인스턴스화\n",
        "- 옵티마이저, 손실 함수, 모델 훈련 성능 지표 정의\n",
        "- 정의된 모델 훈련/검증 루틴을 사용해 모델 훈련 루프 실행"
      ],
      "metadata": {
        "id": "wtCYcQRkVukB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **기본 설정**"
      ],
      "metadata": {
        "id": "pkuBzhDMXIUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_SIZE = 64 # batch size\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 장치\n",
        "\n",
        "train_data_iterator, valid_data_iterator, test_data_iterator = data.BucketIterator.splits(\n",
        "    (train_dataset, valid_dataset, test_dataset),\n",
        "    batch_size = B_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "vOmhsw0fXKGi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### GPU를 위한 환경 설정\n",
        "## If you are training using GPUs, we need to use the following function for the pack_padded_sequence method to work\n",
        "## (reference : https://discuss.pytorch.org/t/error-with-lengths-in-pack-padded-sequence/35517/3)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_tensor_type(torch.cuda.FloatTensor)"
      ],
      "metadata": {
        "id": "YuI1IguYXYeJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, PackedSequence\n",
        "\n",
        "def cuda_pack_padded_sequence(input, lengths, batch_first = False, enforce_sorted = True):\n",
        "  lengths = torch.as_tensor(lengths, dtype = torch.int64)\n",
        "  lengths = lengths.cpu()\n",
        "\n",
        "  if enforce_sorted:\n",
        "    sorted_indices = None\n",
        "\n",
        "  else:\n",
        "      lengths, sorted_indices = torch.sort(lengths, descending = True)\n",
        "      sorted_indices = sorted_indices.to(input.device)\n",
        "      batch_dim = 0 if batch_first else 1\n",
        "      input = input.index_select(batch_dim, sorted_indices)\n",
        "\n",
        "  data, batch_sizes = torch._C._VariableFunctions._pack_padded_sequence(input, lengths, batch_first)\n",
        "\n",
        "  return PackedSequence(data, batch_sizes, sorted_indices)"
      ],
      "metadata": {
        "id": "9dMD_tWLXoMS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **a) 모델 인스턴스화**"
      ],
      "metadata": {
        "id": "lUK0FDepWCkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### LSTM 클래스 정의\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, vocabulary_size, embedding_dimension, hidden_dimension, output_dimension, dropout, pad_index):\n",
        "    super().__init__()\n",
        "    self.embedding_layer = nn.Embedding(vocabulary_size, embedding_dimension, padding_idx = pad_index)\n",
        "    self.lstm_layer = nn.LSTM(embedding_dimension,\n",
        "                              hidden_dimension,\n",
        "                              num_layers = 1,\n",
        "                              bidirectional = True,\n",
        "                              dropout = dropout)\n",
        "    self.fc_layer = nn.Linear(hidden_dimension * 2, output_dimension)\n",
        "    self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, sequence, sequence_lengths = None):\n",
        "    if sequence_lengths is None:\n",
        "      sequence_lengths = torch.LongTensor([len(sequence)])\n",
        "\n",
        "    # sequence := (sequence_length, batch_size)\n",
        "    embedded_output = self.dropout_layer(self.embedding_layer(sequence))\n",
        "\n",
        "    # embedded_output := (sequence_length, batch_size, embedding_dimension)\n",
        "    if torch.cuda.is_available():\n",
        "      packed_embedded_output = cuda_pack_padded_sequence(embedded_output, sequence_lengths)\n",
        "    else:\n",
        "      packed_embedded_output = nn.utils.rnn.pack_padded_sequence(embedded_output, sequence_lengths)\n",
        "\n",
        "    packed_output, (hidden_state, cell_state) = self.lstm_layer(packed_embedded_output)\n",
        "    # hidden_state := (num_layers * num_directions, batch_size, hidden_dimension)\n",
        "    # cell_state := (num_layers * num_directions, batch_size, hidden_dimension)\n",
        "\n",
        "    op, op_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "    # op := (sequence_length, batch_size, hidden_dimension * num_directions)\n",
        "\n",
        "    hidden_output = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n",
        "    # hidden_output := (batch_size, hidden_dimension * num_directions)\n",
        "\n",
        "    return self.fc_layer(hidden_output)"
      ],
      "metadata": {
        "id": "kwO0IddhWyaZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIMENSION = len(TEXT_FIELD.vocab)\n",
        "EMBEDDING_DIMENSION = 100\n",
        "HIDDEN_DIMENSION = 32\n",
        "OUTPUT_DIMENSION = 1\n",
        "DROPOUT = 0.5\n",
        "PAD_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.pad_token]\n",
        "\n",
        "lstm_model = LSTM(INPUT_DIMENSION,\n",
        "                  EMBEDDING_DIMENSION,\n",
        "                  HIDDEN_DIMENSION,\n",
        "                  OUTPUT_DIMENSION,\n",
        "                  DROPOUT,\n",
        "                  PAD_INDEX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bemg1kEXZk6h",
        "outputId": "3a2775d9-d34d-4801-a77b-fb3924744bd1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b) 토큰 추가하기**\n",
        "- 사전에 두 개의 특수 토큰을 추가\n",
        "  - 사전에 없는 단어를 위한 `unknown_token`\n",
        "  - 시퀀스 패딩을 위해 추가되는 토큰인 `padding_token`"
      ],
      "metadata": {
        "id": "sZJcTYSkZLtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.unk_token]\n",
        "\n",
        "lstm_model.embedding_layer.weight.data[UNK_INDEX] = torch.zeros(EMBEDDING_DIMENSION)\n",
        "lstm_model.embedding_layer.weight.data[PAD_INDEX] = torch.zeros(EMBEDDING_DIMENSION)"
      ],
      "metadata": {
        "id": "JGUElfEBZUyL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **c) 옵티마이저, 손실함수 정의**"
      ],
      "metadata": {
        "id": "brFa-ZYyZ8TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optim = torch.optim.Adam(lstm_model.parameters())\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "lstm_model = lstm_model.to(device)\n",
        "loss_func = loss_func.to(device)"
      ],
      "metadata": {
        "id": "FsGOqz1wZ_qc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **d) 정확도 계산 함수 정의**"
      ],
      "metadata": {
        "id": "czDm7kBCaFvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_metric(predictions, ground_truth):\n",
        "  \"\"\"\n",
        "  Returns 0-1 accuracy for the given set of predictions and ground truth\n",
        "  \"\"\"\n",
        "  # round predictions to either 0 or 1\n",
        "  rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
        "  success = (rounded_predictions == ground_truth).float() # convert into float for division\n",
        "\n",
        "  accuracy = success.sum() / len(success)\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "_3_zaplOaI6s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **e) 훈련/검증 루틴 정의**"
      ],
      "metadata": {
        "id": "1LI0WUU0aW8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**훈련 루틴 정의**"
      ],
      "metadata": {
        "id": "XASYlbKIachd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_iterator, optim, loss_func):\n",
        "  loss = 0\n",
        "  accuracy = 0\n",
        "\n",
        "  # 훈련 mode\n",
        "  model.train()\n",
        "\n",
        "  for curr_batch in data_iterator:\n",
        "    optim.zero_grad()\n",
        "    sequence, sequence_lengths = curr_batch.text\n",
        "    preds = lstm_model(sequence, sequence_lengths).squeeze(1)\n",
        "\n",
        "    loss_curr = loss_func(preds, curr_batch.label)\n",
        "    accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
        "\n",
        "    loss_curr.backward()\n",
        "    optim.step()\n",
        "\n",
        "    loss += loss_curr.item()\n",
        "    accuracy += accuracy_curr.item()\n",
        "\n",
        "  return loss/len(data_iterator), accuracy/len(data_iterator)"
      ],
      "metadata": {
        "id": "17przLECaZ8m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**검증 루틴 정의**"
      ],
      "metadata": {
        "id": "vytezBToaySw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, data_iterator, loss_func):\n",
        "  loss = 0\n",
        "  accuracy = 0\n",
        "\n",
        "  # 평가 mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for curr_batch in data_iterator:\n",
        "      sequence, sequence_lengths = curr_batch.text\n",
        "      preds = model(sequence, sequence_lengths).squeeze(1)\n",
        "\n",
        "      loss_curr = loss_func(preds, curr_batch.label)\n",
        "      accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
        "\n",
        "      loss += loss_curr.item()\n",
        "      accuracy += accuracy_curr.item()\n",
        "\n",
        "  return loss/len(data_iterator), accuracy/len(data_iterator)"
      ],
      "metadata": {
        "id": "11eLDGLra0yX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **f) Run!!**\n",
        "- 모델을 훈련시키고 가장 성능이 좋은 모델을 저장"
      ],
      "metadata": {
        "id": "0Yu5NOx9bQJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "best_validation_loss = float('inf')\n",
        "\n",
        "for ep in range(num_epochs):\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  training_loss, train_accuracy = train(lstm_model, train_data_iterator, optim, loss_func)\n",
        "  validation_loss, validation_accuracy = validate(lstm_model, valid_data_iterator, loss_func)\n",
        "\n",
        "  time_end = time.time()\n",
        "  time_delta = time_end - time_start\n",
        "\n",
        "  if validation_loss < best_validation_loss:\n",
        "    best_validation_loss = validation_loss\n",
        "    torch.save(lstm_model.state_dict(), 'lstm_model.pt')\n",
        "\n",
        "  print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
        "  print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
        "  print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "jWxLFJqHbbec",
        "outputId": "29ae6ed1-eb50-4202-f804-b5fa04c3438a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number: 1 | time elapsed: 1348.0087351799011s\n",
            "training loss: 0.684 | training accuracy: 55.07%\n",
            "validation loss: 0.665 |  validation accuracy: 60.46%\n",
            "\n",
            "epoch number: 2 | time elapsed: 1266.6256999969482s\n",
            "training loss: 0.647 | training accuracy: 62.22%\n",
            "validation loss: 0.806 |  validation accuracy: 58.85%\n",
            "\n",
            "epoch number: 3 | time elapsed: 1174.1245894432068s\n",
            "training loss: 0.571 | training accuracy: 70.23%\n",
            "validation loss: 0.662 |  validation accuracy: 70.79%\n",
            "\n",
            "epoch number: 4 | time elapsed: 1147.509672164917s\n",
            "training loss: 0.506 | training accuracy: 75.53%\n",
            "validation loss: 0.618 |  validation accuracy: 71.26%\n",
            "\n",
            "epoch number: 5 | time elapsed: 1091.2177605628967s\n",
            "training loss: 0.461 | training accuracy: 78.53%\n",
            "validation loss: 0.593 |  validation accuracy: 71.91%\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2e73c6ee841e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mtraining_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-3fb932e0e313>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_iterator, optim, loss_func)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-0dcbbbadc39c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequence, sequence_lengths)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mpacked_embedded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_embedded_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m# hidden_state := (num_layers * num_directions, batch_size, hidden_dimension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# cell_state := (num_layers * num_directions, batch_size, hidden_dimension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    880\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    883\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    884\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **g) 모델 검증**\n",
        "- 가장 성능이 좋았던 모델을 로딩해서 테스트 셋에서 검증"
      ],
      "metadata": {
        "id": "VyOhJAYgcU1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.load_state_dict(torch.load('lstm_model.pt'))\n",
        "\n",
        "test_loss, test_accuracy = validate(lstm_model, test_data_iterator, loss_func)\n",
        "\n",
        "print(f'test loss: {test_loss:.3f} | test accuracy: {test_accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsZ7eQvUcXb9",
        "outputId": "777d4d61-cee0-4247-dcc4-f333e2eb010e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 0.632 | test accuracy: 70.52%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **h) 추론**\n",
        "- 감성 추론 함수 정의\n",
        "- 훈련된 모델에 영화 리뷰를 수동으로 입력해 실행"
      ],
      "metadata": {
        "id": "-u-2728ZctOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 감성 추론을 위한 함수\n",
        "\n",
        "def sentiment_inference(model, sentence):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  # text transformations\n",
        "  tokenized = data.get_tokenizer(\"basic_english\")(sentence)\n",
        "  tokenized = [TEXT_FIELD.vocab.stoi[t] for t in tokenized]\n",
        "\n",
        "  # model inference\n",
        "  model_input = torch.LongTensor(tokenized).to(device)\n",
        "  model_input = model_input.unsqueeze(1)\n",
        "\n",
        "  pred = torch.sigmoid(model(model_input))\n",
        "\n",
        "  return pred.item()"
      ],
      "metadata": {
        "id": "mjUdXajPcw1d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 훈련된 모델에 영화 리뷰를 수동으로 입력해 실행\n",
        "\n",
        "print(sentiment_inference(lstm_model, \"This film is horrible\"))\n",
        "print(sentiment_inference(lstm_model, \"Director tried too hard but this film is bad\"))\n",
        "print(sentiment_inference(lstm_model, \"Decent movie, although could be shorter\"))\n",
        "print(sentiment_inference(lstm_model, \"This film will be houseful for weeks\"))\n",
        "print(sentiment_inference(lstm_model, \"I loved the movie, every part of it\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-VRgGYEdLpN",
        "outputId": "79844d23-b601-4dd9-926f-d20ac7b7d36f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10918296873569489\n",
            "0.043620288372039795\n",
            "0.700039803981781\n",
            "0.41704854369163513\n",
            "0.9363043308258057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LSTM 모델이 검증셋에 대해 성능 측면에서 RNN 모델보다 뛰어남\n",
        "- 드롭아웃을 통한 과적합 방지\n",
        "- 양방향 LSTM 아키텍처는 영화 리뷰 텍스트 문장에서 순차적 패턴을 학습함"
      ],
      "metadata": {
        "id": "icMphprQdaHR"
      }
    }
  ]
}