{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c25c8f",
   "metadata": {},
   "source": [
    "## **라이브러리 호출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348a082d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e959748784dd4fe184d520cd35bbb277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faaff9ef5a4349c9a4ee0d1b545fa36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3be6c07f32e41fc8d6dd9b78ee1bf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3511bb",
   "metadata": {},
   "source": [
    "## **문장 토크나이징**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b23ea55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '나는', '파', '##이', '##토', '##치를', '이', '##용한', '딥', '##러', '##닝', '##을', '학', '##습', '##중', '##이다', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"나는 파이토치를 이용한 딥러닝을 학습중이다.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\" # 문장의 시작은 [CLS], 끝은 [SEP]로 형태 맞추기\n",
    "tokenized_text = tokenizer.tokenize(marked_text) # 사전 훈련된 버트 토크나이저 활용 -> 문장 to 단어\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a639263",
   "metadata": {},
   "source": [
    "## **데이터 준비**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d76f8",
   "metadata": {},
   "source": [
    "### **훈련시킬 텍스트 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee53fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "과             8,898\n",
      "##수          15,891\n",
      "##원에         108,280\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##가          11,287\n",
      "많             9,249\n",
      "##았다         27,303\n",
      ".               119\n",
      "친             9,781\n",
      "##구          17,196\n",
      "##가          11,287\n",
      "나             8,982\n",
      "##에게         26,212\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##했다         12,490\n",
      ".               119\n",
      "백             9,331\n",
      "##설          31,928\n",
      "##공          28,000\n",
      "##주는         100,633\n",
      "독             9,088\n",
      "##이          10,739\n",
      "든             9,115\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##를          11,513\n",
      "먹             9,266\n",
      "##었다         17,706\n",
      ".               119\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "text = \"과수원에 사과가 많았다.\" \\\n",
    "       \"친구가 나에게 사과했다.\"\\\n",
    "       \"백설공주는 독이 든 사과를 먹었다.\"\n",
    "\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\" \n",
    "tokenized_text = tokenizer.tokenize(marked_text) # 문장을 토큰으로 분리\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text) # 토큰 문자열에 인덱스 매핑\n",
    "\n",
    "for tup in zip(tokenized_text, indexed_tokens): # 단어 & 인덱스 출력\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08558b76",
   "metadata": {},
   "source": [
    "**문장 인식 단위 지정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b29cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d17e94f",
   "metadata": {},
   "source": [
    "**텐서 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c27f4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a90e750",
   "metadata": {},
   "source": [
    "### **모델링**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8534d0",
   "metadata": {},
   "source": [
    "**모델 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf8cc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e98c1d1bc746b096c6cece74966609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-multilingual-cased',\n",
    "                                  output_hidden_states = True,)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4ad6bd",
   "metadata": {},
   "source": [
    "- 12개의 계층(임베딩 계층 포함 시 13개의 계층)으로 구성되어 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53520580",
   "metadata": {},
   "source": [
    "**모델 훈련**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51930fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): # 모델 평가 시에는 기울기 계산 x\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    hidden_states = outputs[2] # 네트워크의 은닉 상태 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eebd8f8",
   "metadata": {},
   "source": [
    "**모델 정보 확인**\n",
    "- 은닉 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f3c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계층 수: 13   (initial embeddings + 12 BERT layers)\n",
      "배치 수: 1\n",
      "토큰 수: 33\n",
      "은닉층 유닛 수: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"계층 수:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"배치 수:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"토큰 수:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"은닉층 유닛 수:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491de7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "은닉 상태의 유형:  <class 'tuple'>\n",
      "각 계층에서의 텐서 형태:  torch.Size([1, 33, 768])\n"
     ]
    }
   ],
   "source": [
    "# 4개 차원(계층, 배치, 토큰, 은닉층 유닛) -> 3개 차원(토큰, 계층, 은닉층 유닛)\n",
    " \n",
    "print('은닉 상태의 유형: ', type(hidden_states))\n",
    "print('각 계층에서의 텐서 형태: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de818ae",
   "metadata": {},
   "source": [
    "**텐서 형태 변경**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad80efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 33, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 계층의 텐서 결합은 stack 활용\n",
    "token_embeddings = torch.stack(hidden_states, dim = 0)\n",
    "\n",
    "# 최종 텐서 형태 출력\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10648a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 33, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 최종 텐서에서 불필요한 '배치' 차원 제거\n",
    "\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim = 1) # 배치 차원(dim = 1) 제거\n",
    "token_embeddings.size() # 배치 차원 제거 후 최종 텐서 형태 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af1391",
   "metadata": {},
   "source": [
    "**텐서 차원 변경**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "037062f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 13, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = token_embeddings.permute(1,0,2) # 차원 변환 시 활용\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c61a9",
   "metadata": {},
   "source": [
    "**단어 벡터 생성**\n",
    "- 쪼개진 단어에 대한 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "816ea702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태는: 33 x 3072\n"
     ]
    }
   ],
   "source": [
    "token_vecs_cat = [] # 형태를 변경한 벡터를 저장할 리스트\n",
    "\n",
    "for token in token_embeddings:\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim = 0)\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "print ('형태는: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f72695a",
   "metadata": {},
   "source": [
    "**계층을 결합하여 최종 단어 벡터 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bafc204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태는: 33 x 768\n"
     ]
    }
   ],
   "source": [
    "token_vecs_sum = [] # [33, 768] 형태의 토큰을 벡터로 저장\n",
    "for token in token_embeddings: # [33, 12, 768] 형태의 토큰\n",
    "    sum_vec = torch.sum(token[-4:], dim = 0) # 마지막 네 개 계층의 벡터 합산\n",
    "    token_vecs_sum.append(sum_vec) # 'sum_vec'을 활용하여 토큰 표현\n",
    "print ('형태는: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702d6fe",
   "metadata": {},
   "source": [
    "**문장 벡터**\n",
    "- 전체 문장에 대한 단일 벡터 구하기\n",
    "- 전체 길이(768)의 벡터를 생성하는 각 토큰의 두 번째에서 마지막 은닉 계층을 평균화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e98d27f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 임베딩 벡터의 형태: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "token_vecs = hidden_states[-2][0] # 은닉 상태: [13,1,33,768] -> [33, 768]\n",
    "sentence_embedding = torch.mean(token_vecs, dim = 0)\n",
    "print (\"최종 임베딩 벡터의 형태:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb0eda",
   "metadata": {},
   "source": [
    "**토큰 & 인덱스 출력**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4515094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 과\n",
      "2 ##수\n",
      "3 ##원에\n",
      "4 사\n",
      "5 ##과\n",
      "6 ##가\n",
      "7 많\n",
      "8 ##았다\n",
      "9 .\n",
      "10 친\n",
      "11 ##구\n",
      "12 ##가\n",
      "13 나\n",
      "14 ##에게\n",
      "15 사\n",
      "16 ##과\n",
      "17 ##했다\n",
      "18 .\n",
      "19 백\n",
      "20 ##설\n",
      "21 ##공\n",
      "22 ##주는\n",
      "23 독\n",
      "24 ##이\n",
      "25 든\n",
      "26 사\n",
      "27 ##과\n",
      "28 ##를\n",
      "29 먹\n",
      "30 ##었다\n",
      "31 .\n",
      "32 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    print (i, token_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec282d",
   "metadata": {},
   "source": [
    "**단어 벡터 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b97cb6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사과가 많았다 tensor([-0.5844, -4.0836,  0.4906,  0.8915, -1.8054])\n",
      "나에게 사과했다 tensor([-0.8631, -3.4047, -0.7351,  0.9805, -2.6700])\n",
      "사과를 먹었다 tensor([ 0.6756, -0.3618,  0.0586,  2.2050, -2.4193])\n"
     ]
    }
   ],
   "source": [
    "print(\"사과가 많았다\", str(token_vecs_sum[6][:5]))\n",
    "print(\"나에게 사과했다\", str(token_vecs_sum[10][:5]))\n",
    "print(\"사과를 먹었다\", str(token_vecs_sum[19][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694a048",
   "metadata": {},
   "source": [
    "**코사인 유사도 계산**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9763196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*유사한* 의미에 대한 벡터 유사성:  0.86\n",
      "*다른* 의미에 대한 벡터 유사성:  0.91\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "diff_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[27])\n",
    "same_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[16])\n",
    "\n",
    "print('*유사한* 의미에 대한 벡터 유사성:  %.2f' % same_apple)\n",
    "print('*다른* 의미에 대한 벡터 유사성:  %.2f' % diff_apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc26ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
